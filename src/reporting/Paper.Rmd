---
title: "IMDb Runtime & Ratings Analysis (2011–2020)"
author: "Group 7"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    number_sections: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

library(dplyr)
library(tidyr)
library(readr)
library(knitr)
library(here)
library(sandwich)
library(lmtest)
library(car)
```

## Motivation

In today’s world, movie ratings play an integral part when viewers decide which movie to watch. Among the many factors that influence the rating of a movie, runtime stands out as a relevant one when it comes to audience evaluation. Previously, a study by Choudhary et al. (2024) found runtime to be a statistically significant variable, influencing the rating of a movie across different genres, though the magnitude of this effect varied between genres. This raises the question about exploring not only the magnitude, but also the direction of the runtime effect. On the one hand, longer movies allow for more complex storytelling and character development, but on the other hand, decreasing attention spans (Hayes, 2024) among people may actually drive longer movie ratings down.

Previous research suggests a significant relationship between movie genres and their ratings, however often note that isolation of the genre variable is not clearly attainable (Choudhary et al., 2024). While there is no clear consensus in the literature on which genres consistently receive the highest ratings, Matthews (2021) argues that audience expectations are more structured for mainstream genres such as drama, action, and comedy than for niche categories. In these popular genres, ratings often reflect not only film quality but also how well a movie aligns with established genre conventions. Building on this, the present research focuses specifically on adventure, action, and comedy, as these genres have consistently generated the highest box office revenues in North America over the past decades (Statista, 2025). Adventure and action dominate due to their large-scale productions, international appeal, and substantial commercial success, while comedy plays a complementary role by reflecting cultural preferences and offering insights into audience diversity. Together, these genres allow for a balanced analysis that captures both the financial strength of blockbuster categories and the cultural relevance of humor-driven films.

In addition to examining the relationship between runtime, genre, and IMDb ratings, it is also important to define a clear time interval for the research. The global Netflix subscriber data provides a useful benchmark: in early 2013, Netflix had around 30 million paid subscribers, but by 2015 that number had more than doubled to over 70 million (Netflix, 2025). This rapid acceleration reflects the point at which streaming shifted from an emerging model to a mainstream mode of media consumption, making 2015 a suitable cutoff year. Streaming services mark a natural cutoff point because they changed how runtimes are perceived: before streaming, films were optimized for theatrical showings and ticket sales, while streaming enabled more flexibility in length. As audiences gained on-demand access, tolerance for both shorter and longer runtimes shifted, making streaming adoption a key turning point for analyzing runtime effects on IMDb ratings. To ensure balanced group sizes around our cutoff, we divided the data into two equal-length periods: 2011–2015 and 2016–2020. This allows us to compare runtime–rating relationships across time while keeping the number of films per period reasonably similar. Accordingly, the research will compare films released between 2011 and 2015 with those released between 2016 and 2020.

Thus, the research question for this project is defined as “How does runtime influence IMDb ratings, and how is this relationship moderated by genre (Adventure, Action and Comedy) when comparing films released between 2011 and 2015 to those released between 2016 and 2020?” This research addresses a gap in the currently existing literature of factors that influence audience reception of movies such as IMDb ratings by investigating how the release year (between 2011 and 2015 versus between 2016 and 2020) and genre (Adventure, Action and Comedy) have a moderating effect on the relationship between runtime and IMDb ratings of movies. Previous research looked at the individual effects of runtime, release year and genre (Horror, Comedy and Action) on IMDb ratings while this research also looks at the relative effects of these variables and how they interact with each other.

Further, this research is relevant to different marketing stakeholders in the movie industry such as marketing managers of movie studios, streaming platforms and cinemas. By providing valuable insights on the runtime preferences of audiences these can be used for example by movie studios to create movies across different genres with an optimal runtime and by streaming platforms and cinemas to find the optimal marketing strategy to movies of different runtimes and genres.

## Data

- We are using two files from the IMDB database:
  1) title.basics.tsv.gz (contains unique identifier of the title, the type/format of the title, original title, the release year of a title, TV Series end year, primary runtime of the title, genres)
  2) title.ratings.tsv.gz (contains unique identifier of the title, averageRating and number of votes the title has received)
     
- The final dataset includes 20144 observations. 
A variable description / operationalisation table is below.

## Variable Description and Operationalisation

| Variable        | Type              | Source              | Operationalisation (How it is measured/defined)                                 |
|-----------------|-------------------|---------------------|---------------------------------------------------------------------------------|
| `Rating`        | Dependent         | `title.ratings`     | `averageRating` (on a scale of 1-10, continuous)                                |
| `Runtime10`     | Independent       | `title.basics`      | (`runtimeMinutes` - mean(`runtimeMinutes`))/10                                  |
| `Genre`         | Moderator         | `title.basics`      | Comedy (reference), Adventure (dummy), Action (dummy)                           |
| `YearGroup`     | Moderator         | `title.basics`      | 2011-2015 (reference), 2016-2020 (dummy)                                        |  
| `numVotes`      | Control           | `title.rating`      | Total IMDb votes                                                                |
| `logVotes`      | Control           |  Derived            | log10(`numVotes`). Interpreted as +1 = 10x more votes                           |
| `Intercept`     | Derived           |  Model              | Comedy movie, 2011-2015, mean `runtimeMinutes`, mean `logVotes`                 |

To ensure data quality and meaningful analysis, we applied the following filters to the dataset:

1) Runtime filter: We excluded movies with a runtime below 30 minutes.

Rationale: Very short films (e.g., shorts, experimental pieces) are structurally different from feature-length movies, and including them would bias our analysis of how runtime affects ratings.

2) Vote count filter: We excluded movies with fewer than 50 votes.

Rationale: IMDb ratings for movies with very few votes are often unstable and unreliable. Setting a threshold of 50 votes ensures that our dataset contains movies with sufficient audience engagement to provide a more representative measure of audience opinion.

### Handling Missing Values (Runtime)

During the data preparation phase, we observed that some movies in the IMDb dataset had missing values for runtimeMinutes. Further exploration revealed that these missing values were not randomly distributed: they tended to occur more frequently in certain genres and time periods. Because runtime is our main independent variable, we could not simply drop these movies, as that might bias our analysis.

To address this, we applied a median imputation strategy grouped by genre and release period. Specifically:
Movies were grouped by genre (Comedy, Action, Adventure) and release year group (2011–2015 vs. 2016–2020).
Within each group, missing runtimes were replaced with the median runtime of that group. (Median was chosen instead of the mean because it is more robust to outliers.)
This approach ensures that our dataset remains complete without artificially inflating runtimes or discarding a large number of observations. 

## Method

For this research we will perform a multiple linear regression with interaction terms to find ou  t whether the runtime of a movie (continuous) influences its IMDb rating (continuous) and whether a film’s genre (Comedy, Adventure or Action) (categorical) and the release period (2011-2015 vs. 2016-2020) (categorical) influence this relationship. The runtime is the independent variable, the IMDb rating is the dependent variable and the two moderators are Genre (Comedy vs. Adventure vs. Action) and Release Period (2011-2015 vs. 2016-2020). Further, we will include the number of IMDb votes (expressed as a log-scaled variable) as a control variable since ratings based on more votes are usually more stable and reliable (Xie & Lui, 2013). We have chosen for a multiple linear regression with interaction terms as this is the most suitable way to combine these variable types, a continuous independent and dependent variable and two categorical moderators, into one model.
This will lead to the following model:
Rating = X₀ + β₁·Runtime10 + β₂·Adventure + β₃·Action + β₄·Yeargroup<sub>2016–2020</sub> + β₅·(Runtime10 × Adventure) + β₆·(Runtime10 × Action) + β₇·(Runtime10 × Yeargroup<sub>2016–2020</sub>) + β₈·log₁₀(Votes) + ϵ  

where:  
- β₁ = How the effect of +10 minutes runtime on IMDb ratings changes for Comedy movies released in 2011–2015  
- β₂, β₃ = How the effect of +10 minutes runtime on IMDb ratings changes for Adventure and Action movies compared to Comedy movies  
- β₄ = How the IMDb ratings change between movies released in <sub>2016–2020</sub> compared to movies released in 2011–2015  
- β₅, β₆ = How the effect of +10 minutes runtime on IMDb ratings changes for Adventure and Action movies compared to Comedy movies  
- β₇ = How the effect of +10 minutes runtime on IMDb ratings changes for movies released in 2016–2020 compared to 2011–2015  
- β₈ = How the IMDb ratings change between movies when the number of votes increases by a factor of 10  

We began with a descriptive analysis to explore the data. This included
examining trends over time, looking at the distributions of ratings,
votes (on a log scale), and runtimes, and summarizing results by both
year and genre (focusing on Action, Comedy, and Adventure). We conducted
the analysis in two steps:

-   **Descriptive analysis:**\
    We first explored the data by examining trends over time, the
    distributions of IMDb ratings, votes (on a log scale), and runtimes,
    and summary statistics by both year and genre (Action, Comedy, and
    Adventure).

-   **Regression analysis:**\
    We then estimated an ordinary least squares (OLS) regression with
    interaction terms to test whether a film’s runtime influences its
    IMDb rating, and whether this relationship differs by genre and
    release period.

To control for rating stability, we included the number of IMDb
    votes (log₁₀-transformed) as a covariate. Robust HC3 standard errors
    were used to account for heteroskedasticity, and we checked
    diagnostics including heteroskedasticity tests, residual normality,
    and variance inflation factors (VIF).

## Descriptive Results
```{r descriptive-tables, echo=FALSE, message=FALSE, warning=FALSE}
movies <- readr::read_csv(here::here("gen", "output", "final_dataset.csv"),
                          show_col_types = FALSE)

genre_tbl <- movies %>%
  tidyr::separate_rows(genres, sep = ",") %>%
  dplyr::filter(genres %in% c("Action","Comedy","Adventure")) %>%
  dplyr::group_by(genres) %>%
  dplyr::summarise(
    n_films      = dplyr::n(),
    mean_rating  = mean(averageRating, na.rm = TRUE),
    sd_rating    = sd(averageRating, na.rm = TRUE),
    mean_votes   = mean(numVotes, na.rm = TRUE),
    mean_runtime = mean(runtimeMinutes, na.rm = TRUE),
    .groups = "drop"
  )

knitr::kable(genre_tbl, digits = 2, caption = "Summary by Genre")

# 3) Year summary
year_tbl <- movies %>%
  dplyr::group_by(startYear) %>%
  dplyr::summarise(
    n_films      = dplyr::n(),
    mean_rating  = mean(averageRating, na.rm = TRUE),
    mean_votes   = mean(numVotes, na.rm = TRUE),
    mean_runtime = mean(runtimeMinutes, na.rm = TRUE),
    .groups = "drop"
  )

knitr::kable(year_tbl, digits = 2, caption = "Summary by Year")
```

### Descriptive figures

#### Film output over time 
The number of films released annually increased steadily from 2011 until around 2018, reaching a peak of over 2,000 titles per year. After 2018, we observe a decline in output, with a particularly sharp drop in 2020. This is likely due to the disruptions in global film production during the COVID-19 pandemic.
<br><br> 
<img src="../gen/output/desc-analysis-figures/films_per_year.png" alt="Number of films per year" style="width:60%"> 
<br> 

#### Runtime patterns 
Since runtime is our main explanatory variable, we first explore its distribution across time and genres. This helps establish whether there is enough variation in runtimes to meaningfully relate them to ratings.

##### Average runtime per year
The average runtime of films remained remarkably consistent across the 2011–2020 period, fluctuating only within a narrow range of about 97–102 minutes. This stability suggests that runtime norms were fairly entrenched across the decade.
<br><br> 
<img src="../gen/output/desc-analysis-figures/avgruntime_per_year.png" alt="Average runtime per year" style="width:60%">
<br> 

##### Distribution of runtimes
Most films fell into a range of 80–120 minutes, with a clear peak around 95–105 minutes. Only a small share of films were much shorter or longer, indicating that runtimes cluster strongly around conventional feature-length standards. 
<br><br> 
<img src="../gen/output/desc-analysis-figures/dist_of_runtimes.png" alt="Distribution of runtimes" style="width:60%">
<br> 

##### Runtime distribution by genre
When broken down by genre, Action films showed the highest median runtimes and the widest spread, reflecting the blockbuster tendency toward longer movies. Adventure films were slightly shorter but still above 95 minutes on average, while Comedies were noticeably shorter and less variable, clustering tightly around the 90–100 minute range.
<br><br> 
<img src="../gen/output/desc-analysis-figures/runtimedist_by_genre.png" alt="Runtime distribution by genre" style="width:60%">
<br> 

#### IMDb ratings (main outcome)
Ratings are the key dependent variable of the research. By describing their distribution across years and genres, we can see whether patterns emerge that runtime might help explain.

##### Average rating per year
Mean IMDb ratings across all films were stable at around 5.6 for most of the decade. However, after 2017 a modest decline is visible, suggesting either changes in the kinds of films being produced or shifts in audience evaluation.
<br><br> 
<img src="../gen/output/desc-analysis-figures/avgrating_per_year.png" alt="Average rating per year" style="width:60%">
<br> 

##### Distribution of IMDb ratings
The histogram shows that most films score between 5 and 6, with relatively few extreme ratings. Very high ratings (above 8) are rare, which reflects IMDb’s tendency toward a compressed rating scale centered in the mid-range.
<br><br> 
<img src="../gen/output/desc-analysis-figures/dist_of_ratings.png" alt="Distribution of IMDb ratings" style="width:60%">
<br> 

##### Average rating by genre
Adventure films achieved the highest average ratings (≈5.7), slightly above Comedy and Action. Comedies and Action movies clustered more closely together (≈5.5 to 5.6), indicating that modest genre differences in audience evaluations exist.
<br><br> 
<img src="../gen/output/desc-analysis-figures/avgrating_per_genre.png" alt="Average rating by genre" style="width:60%">
<br> 

##### Heatmap: average IMDb rating per Year x Genre
Across time, all three genres showed stable ratings without major trends. Adventure films consistently outperformed the others, while Action films slightly underperformed, but the differences were small. No single year shows any significant spikes or drops for any genre.
<br><br> 
<img src="../gen/output/desc-analysis-figures/heatmap_of_averagerating_per_year.png" alt="Heatmap rating by year × genre" style="width:60%">
<br> 

#### Votes (control variable)
Finally, we consider votes, which serve as a control variable in the regression analysis. Audience size matters, because ratings based on larger numbers of votes are seen as more stable and reliable.

##### Distribution of votes (log scale)
The vote distribution is highly right-skewed: the majority of films received only a few hundred or thousand votes, while a small number attracted hundreds of thousands or even millions. This reflects the blockbuster vs. niche divide in audience reach.
<br><br> 
<img src="../gen/output/desc-analysis-figures/logdist_of_votes.png" alt="Distribution of votes (log scale)" style="width:60%">
<br> 

##### Average number of votes by genre
Adventure films were the most popular in terms of audience engagement, receiving the highest average vote counts. Action films also attracted more attention and votes, while Comedies had fewer votes on average, which might suggest smaller or more fragmented audiences.
<br><br> 
<img src="../gen/output/desc-analysis-figures/avgvotes_per_genre.png" alt="Average votes by genre" style="width:60%">
<br> 

## Regression Results

```{r regression-model, echo=FALSE, message=FALSE, warning=FALSE}
# Load dataset
merged_df <- readr::read_csv(here::here("gen", "output", "final_dataset.csv"),
                             show_col_types = FALSE)

# Model specification
merged_df <- merged_df %>% mutate(
  logVotes  = log10(numVotes),
  Runtime10 = (runtimeMinutes - mean(runtimeMinutes, na.rm = TRUE)) / 10,
  Genre      = factor(Genre, levels = c("Comedy","Adventure","Action")),
  year_group = factor(year_group, levels = c("2011-2015","2016-2020"))
)

model <- lm(averageRating ~ Runtime10*Genre + Runtime10*year_group + logVotes,
            data = merged_df)

# Robust SEs + regression results
robust_se  <- vcovHC(model, type = "HC3")
reg_results <- coeftest(model, vcov = robust_se)
```

```{r helpers, echo=FALSE, message=FALSE, warning=FALSE}
# Number formatting
fmt   <- function(x, d = 3) formatC(x, format = "f", digits = d)
pstr  <- function(p){
  if (is.na(p)) return("NA")
  if (p < 0.001) return("< 0.001")
  formatC(p, format = "f", digits = 3)
}
est   <- function(term) as.numeric(reg_results[term, "Estimate"])
pval  <- function(term) as.numeric(reg_results[term, "Pr(>|t|)"])

# Higher / lower phrasing
effect_level <- function(term, d = 3){
  e <- est(term)
  if (e < 0) paste0(fmt(abs(e), d), " points lower")
  else if (e > 0) paste0(fmt(abs(e), d), " points higher")
  else "no difference"
}

# Steeper / flatter slopes
effect_slope <- function(term, d = 3){
  e <- est(term)
  if (e < 0) paste0(fmt(abs(e), d), " points flatter per +10 minutes")
  else if (e > 0) paste0(fmt(abs(e), d), " points steeper per +10 minutes")
  else "no change in slope"
}
```

```{r assumption-tests, echo=FALSE, message=FALSE, warning=FALSE}
# Homoscedasticity
assump_df <- cbind(model.frame(model), residuals_lm = resid(model))
lev_res <- leveneTest(residuals_lm ~ Genre * year_group, data = assump_df, center = mean)

# Normality
ks_res <- ks.test(assump_df$residuals_lm, "pnorm",
                  mean = mean(assump_df$residuals_lm),
                  sd   = sd(assump_df$residuals_lm))
set.seed(1)
shap_res <- shapiro.test(sample(assump_df$residuals_lm,
                                size = min(5000, length(assump_df$residuals_lm))))

# Multicollinearity
vif_res <- vif(model)

fmt   <- function(x, d = 3) formatC(x, format = "f", digits = d)
pstr  <- function(p){
  if (is.na(p)) return("NA")
  if (p < 0.001) return("< 0.001")
  formatC(p, format = "f", digits = 3)
}
```

### Model assumptions
- **Homoscedasticity (equal variance):**  
  Levene’s test across Genre × YearGroup gave an F-statistic of 
  `r fmt(lev_res[1,"F value"],2)` (*p* = `r pstr(lev_res[1,"Pr(>F)"])`).  
  Since the test was significant, we conclude residuals are heteroscedastic.  
  To address this, all inference is reported with HC3 robust standard errors.

- **Normality of residuals:**  
  The Kolmogorov–Smirnov test gave D = `r fmt(ks_res$statistic,3)` (*p* = `r pstr(ks_res$p.value)`),  
  and the Shapiro–Wilk test on a subsample of 5,000 residuals gave W = `r fmt(shap_res$statistic,3)` (*p* = `r pstr(shap_res$p.value)`).  
  Both reject strict normality. However, given the large sample size (>20,000 films), minor deviations are not problematic because OLS inference is robust under the central limit theorem.

- **Multicollinearity:**  
  The maximum variance inflation factor (VIF) across predictors was `r round(max(vif_res),2)`,  
  well below the common cutoff of 5. Thus, multicollinearity is not a concern.

**Conclusion:**  
While homoscedasticity and normality assumptions are not fully met, robust HC3 errors ensure valid inference. Multicollinearity is not an issue, and the model can be considered well-specified.

To illustrate these diagnostic checks visually, we next examine the
coefficient plot (showing estimated effects with confidence intervals) and
the residuals vs fitted plot (assessing variance and linearity).

### Model Diagnostics

#### Residuals vs Fitted plot
The residuals vs fitted plot helps assess whether model assumptions of
linearity and equal variance hold:

- Levene’s test indicated heteroscedasticity
  (F = `r fmt(lev_res[1,"F value"],2)`, *p* = `r pstr(lev_res[1,"Pr(>F)"])`),
  and the plot shows some variation in residual spread across fitted values.
  This was addressed by using HC3 robust standard errors.
- Residuals remain centered around zero without strong non-linear patterns,
  supporting the model’s linear specification.

<br>
<img src="../gen/output/regression-results/residuals_vs_fitted.png"
     alt="Residuals vs Fitted plot"
     style="width:50%;max-width:500px">
<br>

### Main results table
<img src="../gen/output/regression-results/regression_table_robust.png"
     alt="Regression results (HC3 robust SEs)" style="width:50%;max-width:500px">
<p style="font-style:italic;">
Ordinary least squares with HC3 robust standard errors.
</p>
<br>

#### Interpretation of Regression Results

- `"Runtime10"` (β₁ = `r fmt(est("Runtime10"))`, *p* = `r pstr(pval("Runtime10"))`):  
  For Comedy films in 2011–2015, each additional 10 minutes is associated with a
  `r fmt(est("Runtime10"))` change in IMDb rating.

- `"GenreAdventure"` (β₂ = `r fmt(est("GenreAdventure"))`, *p* = `r pstr(pval("GenreAdventure"))`):  
  At the average runtime and votes, Adventure films are rated `r effect_level("GenreAdventure")` than Comedy.

- `"GenreAction"` (β₃ = `r fmt(est("GenreAction"))`, *p* = `r pstr(pval("GenreAction"))`):  
  At the average runtime and votes, Action films are rated `r effect_level("GenreAction")` than Comedy.

- `"year_group2016-2020"` (β₄ = `r fmt(est("year_group2016-2020"))`, *p* = `r pstr(pval("year_group2016-2020"))`):  
  At the average runtime and votes, films released in 2016–2020 are rated `r effect_level("year_group2016-2020")` than those in 2011–2015.

- `"Runtime10:GenreAdventure"` (β₅ = `r fmt(est("Runtime10:GenreAdventure"))`, *p* = `r pstr(pval("Runtime10:GenreAdventure"))`):  
  The runtime–rating slope for Adventure vs. Comedy is `r effect_slope("Runtime10:GenreAdventure")`.

- `"Runtime10:GenreAction"` (β₆ = `r fmt(est("Runtime10:GenreAction"))`, *p* = `r pstr(pval("Runtime10:GenreAction"))`):  
  The runtime–rating slope for Action vs. Comedy is `r effect_slope("Runtime10:GenreAction")`.

- `"Runtime10:year_group2016-2020"` (β₇ = `r fmt(est("Runtime10:year_group2016-2020"))`, *p* = `r pstr(pval("Runtime10:year_group2016-2020"))`):  
  The runtime–rating slope in 2016–2020 vs. 2011–2015 is `r effect_slope("Runtime10:year_group2016-2020")`.

- `"logVotes"` (β₈ = `r fmt(est("logVotes"))`, *p* = `r pstr(pval("logVotes"))`):  
  A tenfold increase in votes (log₁₀ + 1) is associated with a `r fmt(est("logVotes"))` change in rating.

**Slopes by group (per +10 minutes):** 

-  Comedy, 2011–2015: `r fmt(est("Runtime10"))`  
-  Adventure, 2011–2015: `r fmt(est("Runtime10") + est("Runtime10:GenreAdventure"))`  
-  Action, 2011–2015: `r fmt(est("Runtime10") + est("Runtime10:GenreAction"))`  
-  Comedy, 2016–2020: `r fmt(est("Runtime10") + est("Runtime10:year_group2016-2020"))`

This table reports the estimated coefficients with HC3 robust standard errors; 
the accompanying coefficient plot below provides a visual summary of these effects 
and their 95% confidence intervals.

#### Coefficient plot
The coefficient plot summarizes the estimated regression effects with 95%
confidence intervals. This makes it clear which predictors are significantly
different from zero and in what direction:

<br>
<img src="../gen/output/regression-results/regression_coefficients.png"
     alt="Coefficient estimates with 95% confidence intervals"
     style="width:55%;max-width:550px">
<br><br>

## Conclusions and Recommendations

### Conclusions  
This study examined how movie runtime influences IMDb ratings and whether this relationship is moderated by genre (Comedy, Adventure, Action) and release period (2011–2015 vs. 2016–2020). Using a dataset of over 20,000 films, we estimated an OLS regression with interaction terms, controlling for audience size through log-transformed vote counts.  

This led to the following key findings:  

- **Runtime effect**: For Comedy films released in 2011–2015 (the reference group), runtime had only a modest effect on IMDb ratings. The slope varied across genres and periods, showing that audience tolerance for longer runtimes depends on context.  
- **Genre differences**: Action films were rated significantly lower than Comedy, while Adventure films were rated slightly higher. Importantly, both Action and Adventure showed different runtime–rating slopes compared to Comedy, suggesting genre conventions influence how audiences perceive film length.  
- **Period differences**: Films released in 2016–2020 were generally rated lower than those from 2011–2015, with some evidence that the runtime effect also shifted in this later period. This aligns with the rise of streaming and potential changes in audience expectations.  
- **Votes as control**: The number of audience votes was a strong predictor, confirming that widely viewed films tend to receive higher and more stable ratings.  

Overall, runtime does matter, but its influence is conditional on genre and release period. Adventure audiences appear more tolerant of longer runtimes than Comedy audiences, while Action audiences penalize longer runtimes more strongly. After 2015, movies overall received slightly lower ratings, indicating shifting audience preferences in the streaming era.  

### Recommendations  

Based on these results, we suggest the following recommendations:  

- **Film studios**:  
  - For *Action* films, keeping runtimes tighter may help maintain audience satisfaction, as longer runtimes appear to reduce ratings.  
  - *Adventure* films can sustain longer runtimes, which may support more complex storytelling without penalizing ratings.  
  - *Comedies* remain best received at shorter, more conventional lengths.  

- **Streaming platforms**:  
  - Since the 2016–2020 period shows lower ratings overall, platforms may need to adjust recommendation algorithms or promotional strategies to counteract declining audience evaluations.  
  - Tailoring recommendations by runtime preferences (e.g., shorter comedies, longer adventures) could improve user satisfaction.  

- **Cinemas and marketing teams**:  
  - Marketing should emphasize “epic scale” and immersion for longer Adventure films, while highlighting pacing and efficiency for Action and Comedy.  
  - Runtime can be a strategic element in positioning films to target audiences.  

### Limitations and Future Research   
This study has several limitations:  

- The analysis focused only on three genres (Comedy, Action, Adventure), excluding others such as Drama or Horror that may behave differently.  
- IMDb ratings, while widely used, are subject to self-selection bias and may not fully reflect general audience opinion.  
- The period split (2011–2015 vs. 2016–2020) captures the rise of streaming but does not account for other industry shifts (e.g., franchise dominance, COVID-19 disruptions).  

Future research could expand to other genres, platforms, and audience measures (e.g., box office revenues, streaming completion rates) to build a fuller picture of how runtime affects audience perception in different contexts.  